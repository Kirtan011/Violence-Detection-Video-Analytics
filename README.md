# Violence-Detection-Video-Analytics
## YOLO11 + R3D-18 + Multi-Object Tracking + Motion Filtering

This repository contains a **real-time violence (fight) detection system** designed for CCTV and surveillance applications.  
It uses deep learning for person detection, action classification, motion analysis, and temporal validation to deliver highly accurate fight alerts.

---

# ğŸ“Œ Features

### âœ… 1. Person Detection â€” *YOLO11*
Detects all people in each frame with high accuracy and speed.

### âœ… 2. Fight Classification â€” *3D CNN (R3D-18)*
A custom-trained **3D ResNet-18** model classifies 16-frame video clips as:
- **Fight**
- **Non-Fight**

### âœ… 3. Multi-Object Tracking (SORT-like)
Tracks every person across frames and assigns a unique ID, enabling:
- Person-specific predictions  
- Temporal stability  
- Fight confirmation per individual  

### âœ… 4. Motion-Based Activity Filtering  
Reduces false positives by classifying each tracked person as:
- **Idle** â†’ ignore  
- **Walking** â†’ ignore  
- **Active movement** â†’ candidate for fight  

### âœ… 5. 2-Second Confirmation Rule  
A fight is only confirmed if:
- Model predicts fight  
- Person is active (not standing/walking)  
- Condition lasts **>= 2 seconds**

This drastically reduces flicker and false alarms.

### âœ… 6. Annotated Output
The system outputs a video with:
- Red bounding boxes  
- Text labels like:  
  `FIGHT 87% (active)`  
Only confirmed fighters are displayed.

---

# ğŸ“‚ Dataset

This project uses the **RWF-2000 dataset**, which contains:
- 2000 surveillance videos  
- Two classes: **Fight / Non-Fight**  
- Train/Validation split maintained as in original paper  

Structure:
```
dataset/
   train/
      Fight/
      NonFight/
   val/
      Fight/
      NonFight/
```

---

# ğŸ§  Model Training

### 1. YOLO11 Detection  
Used to generate:
- Bounding boxes  
- Person tracking  
- Person-level cropped clips  

### 2. R3D-18 Action Classifier  
Trained on the generated clips:
- Input: 16Ã—112Ã—112 frames  
- Labels assigned based on video name (Fight=1, NonFight=0)  
- Achieved **~78â€“80% validation accuracy**

---

# ğŸ—ï¸ System Architecture

```
Video â†’ YOLO Person Detection â†’ Multi-Object Tracking 
      â†’ Per-Person Clip Buffer â†’ R3D-18 Classification 
      â†’ Motion Activity Check â†’ 2-Second Fight Confirmation 
      â†’ Final Annotated Output Video
```

---

# ğŸ“¦ Directory Structure (recommended)

```
violence-detection/
â”‚
â”œâ”€â”€ dataset/ 
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ val/
â”‚
â”œâ”€â”€ workspace/
â”‚   â”œâ”€â”€ detections/       # YOLO detection JSONs
â”‚   â”œâ”€â”€ tracks/           # Tracking JSONs
â”‚   â”œâ”€â”€ frames/           # Optional frame dumps
â”‚   â”œâ”€â”€ clips/            # 16-frame person clips (.npy)
â”‚   â”œâ”€â”€ models/           # Checkpoints + best model
â”‚   â””â”€â”€ inference_outputs/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess_detect.py
â”‚   â”œâ”€â”€ preprocess_track.py
â”‚   â”œâ”€â”€ preprocess_clips.py
â”‚   â”œâ”€â”€ train_classifier.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â””â”€â”€ utils.py
â”‚
â””â”€â”€ README.md
```

---

# â–¶ï¸ How to Run Inference

```bash
python src/inference.py --video Test-Video.mp4
```

This generates:

```
workspace/inference_outputs/Test-Video-Output.mp4
```

---

# ğŸ¤– Technologies Used

- **Python**
- **PyTorch**
- **TorchVision**
- **Ultralytics YOLO**
- **OpenCV**
- **NumPy**

---

# ğŸ› ï¸ Requirements

```
torch
torchvision
ultralytics
opencv-python
numpy
```

Install:

```bash
pip install -r requirements.txt
```

---

# ğŸš€ Applications

- Smart Surveillance  
- Public Safety Monitoring  
- Industrial Safety Systems  
- Smart City Solutions  
- Automated Security Alarms  

---
